<img src='imgs/illustration.gif' align="right" width=200>

<br><br><br><br>

# Few-shot vid2vid
### [Project](https://nvlabs.github.io/few-shot-vid2vid/) | [YouTube](https://youtu.be/8AZBuyEuDqc) | [arXiv](https://arxiv.org/)

Pytorch implementation for few-shot photorealistic video-to-video translation. It can be used for generating human motions from poses, synthesizing people talking from edge maps, or turning semantic label maps into photo-realistic videos. The core of video-to-video translation is image-to-image translation. Some of our work in that space can be found in [pix2pixHD](https://github.com/NVIDIA/pix2pixHD) and [SPADE](https://github.com/NVlabs/SPADE). <br><br>
[Few-shot Video-to-Video Synthesis](https://nvlabs.github.io/few-shot-vid2vid/)  
 [Ting-Chun Wang](https://tcwang0509.github.io/), [Ming-Yu Liu](http://mingyuliu.net/), Andrew Tao, [Guilin Liu](https://liuguilin1225.github.io/), [Jan Kautz](http://jankautz.com/), [Bryan Catanzaro](http://catanzaro.name/)  
 NVIDIA Corporation  
 In Neural Information Processing Systems (**NeurIPS**) 2019  

## Example Results
- Dance Videos
<p align='center'>
  <img src='imgs/dance.gif' width='400'/>
  <img src='imgs/statue.gif' width='400'/>
</p>

- Talking Head Videos
<p align='center'>
  <img src='imgs/face.gif' width='400'/>
  <img src='imgs/mona_lisa.gif' width='400'/>
</p>

- Street View Videos
<p align='center'>
  <img src='imgs/street.gif' width='400'/>  
</p>

## Code Coming Soon